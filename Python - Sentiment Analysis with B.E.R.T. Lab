{"cells":[{"cell_type":"markdown","source":["# Lab 4 Fine-tuning BERT for Sentiment Analysis\n","\n","MSBC 5190 \"Modern Artificial Intelligence\" Spring 2022"],"metadata":{"id":"oFIjOf4SvLhY"},"id":"oFIjOf4SvLhY"},{"cell_type":"markdown","metadata":{"id":"eqvj5RN420Qj"},"source":["In this notebook we will demo how to fine-tune a [BERT](https://arxiv.org/abs/1810.04805) classifier using the Huggingface Transformers library ([1](https://huggingface.co/course/chapter1/1), [2](https://huggingface.co/docs/transformers/quicktour)) and Keras and Tensorflow. We will use sentiment analysis as an example. \n","\n","This lab consists of two parts:\n","\n","**Part I: Fine-tune BERT for sentiment analysis**\n","\n","* play with BERT (Hugging Face implementation): Tokenization, Layers and Output Dimensions  \n","* build a sentiment classifier with BERT from scratch and discuss a couple of options you may have\n","* train the network with various configurations and make observations that will hopefully be helpful\n","\n","**Part II: Fine-tune BERT at a higher level of abstraction**\n","\n","* Fine-tune BERT using TFAutoModelForSequenceClassification\n","\n","Note that we are not attempting to reach state of the art by any means. The purpose of the notebook is to demonstrate how to fine-tune BERT for specific text classification tasks and highlight some of the issues you may want to consider when fine-tuning BERT.\n","\n","*Credit: This notebook is adapted from* [https://github.com/datasci-w266/](https://github.com/datasci-w266/2021-summer-main/blob/master/materials/walkthrough_notebooks/bert-finetuning/BERT_Fine-tuning.ipynb)"],"id":"eqvj5RN420Qj"},{"cell_type":"markdown","source":["We first install transformers and import dependencies"],"metadata":{"id":"6B9hkQcWlRNE"},"id":"6B9hkQcWlRNE"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-1vAo54uxwD","outputId":"7fca3435-1aaa-4183-b7eb-559477c15dc5"},"source":["!pip install -q transformers\n","#!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.5 MB 14.2 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 61.1 MB/s \n","\u001b[K     |████████████████████████████████| 6.8 MB 54.1 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 6.2 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 54.4 MB/s \n","\u001b[?25h"]}],"id":"2-1vAo54uxwD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"FEww-YZS20Qm"},"outputs":[],"source":["import numpy as np\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","import transformers\n","from transformers import BertTokenizer, TFBertModel\n","\n","import logging\n","tf.get_logger().setLevel(logging.ERROR)"],"id":"FEww-YZS20Qm"},{"cell_type":"markdown","metadata":{"id":"X83MDiNo20Qn"},"source":["Let's check for presence of a GPU. We'll need that (or better) if we use transformer models like BERT. "],"id":"X83MDiNo20Qn"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPwnLBI620Qo","outputId":"1563e5d5-310a-4d2d-f756-e7afbccd1464"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"metadata":{},"execution_count":5}],"source":["tf.config.list_physical_devices('GPU')"],"id":"PPwnLBI620Qo"},{"cell_type":"markdown","metadata":{"id":"XTz13UIv20Qp"},"source":["Next, let's specify the versions that we are using:"],"id":"XTz13UIv20Qp"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"GcPe8kid20Qp","outputId":"0fd8ad86-e338-4dd6-8f26-d93b97262f1b"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.8.0'"]},"metadata":{},"execution_count":6}],"source":["tf.__version__"],"id":"GcPe8kid20Qp"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"wwNq4nQA20Qp","outputId":"bbe489b6-3c93-41c2-ed76-b9dfbd4c35a9"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'4.16.2'"]},"metadata":{},"execution_count":7}],"source":["transformers.__version__"],"id":"wwNq4nQA20Qp"},{"cell_type":"markdown","source":["## What is BERT?\n","\n","Bidirectional Encoder Representations from Transformers (BERT) is a Natural Language Processing Model proposed by Google Research in 2018. It is based on a multi-layer bidirectional Transformer, pre-trained on two unsupervised tasks using a large crossdomain corpus:\n","\n","* Masked Language Modeling (MLM): 15% of the words in each sequence are replaced with a [MASK] token. The model then attempts to predict the masked words, based on the context provided by the non-masked ones.\n","* Next Sentence Prediction (NSP): the model receives pairs of sentences as input and learns to predict if the second sentence is the subsequent sentence in the original document.\n","\n","BERT learns contextual representation of words. It is deeply bidirectional, which means that it can learn the context of a word based on all the information contained in the input sequence, joinlty considering previous and subsequent tokens. In fact, the use of MLM objective enables the representation to fuse the left and right contexts, allowing the pre-training of a deep bidirectional language representation model. This is a key difference comparing to previous language representation models like OpenAI GPT, which uses a unidirectional (left-to-right) language model, or ELMo, which uses a shallow concatenation of independently trained left-to-right and right-to-left language models. BERT outperformed many task-specific architectures, advancing the state of the art in a wide range of Natural Language Processing tasks, such as textual entailment, text classification and question answering. [borrowing from post https://riccardo-cantini.netlify.app/post/bert_text_classification]"],"metadata":{"id":"kqCJwGE6lnAt"},"id":"kqCJwGE6lnAt"},{"cell_type":"markdown","source":["## Part I Fine-tune BERT for sentiment analysis"],"metadata":{"id":"YIkxlbefkH-Z"},"id":"YIkxlbefkH-Z"},{"cell_type":"markdown","metadata":{"id":"fOtq4opt20Qp"},"source":["### 1. Getting the data\n","\n","We'll use the IMDB dataset, available from tensorflow_datasets.\n","\n","https://www.tensorflow.org/datasets/catalog/imdb_reviews"],"id":"fOtq4opt20Qp"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340,"referenced_widgets":["c35d295e06ed4283bd29727809b54216","bbb8afed387d48a18bfb6a78440835d4","9c2a5bcad9ec4132a6577a90d24fc154","0c6b274773cc4176bd615d3a698f7d60","b260cc10b4c543a2ad3a26203b2a702a","8fb595e299654cf3a49a63f7f33d58c8","8983a6350a68487596a4501d48c266b3","46b3f1c879ed4e52bfad9eb04710e2d6","49711110f80f4c7ead3d9ba6e878bab7","fc0d2f12f4db40fc98379355d33d3fad","3ebb5986dca843d3860d4ddca5e606a0","fabb341a979a4c90a271a1dc91b9d77e","fad3be436c8442cf8fcfc7a5a330bcd0","47b445186d064cd580597b11a47b87e1","6d323c59c4b14839baace79b773bfdd3","523ac7d2e55c467a9200948d423a6041","bbfb77bca4ef44239503f7674c4f8c09","33875c0e82bc427cab6a8a4ff90136d9","d1dcf05f652d47acb31644a4805af47e","62fa216c14b345cd9ed0fdabace5b1c7","20810f74e68840168bdd9eb30bdf8ede","46e47b077d114a8fabd80d40f1edd2ed","349856e79cdb4d1080a0927d25255bb3","84e8f45820624362b45e516a2c9ef8f9","43b9a5ed213949c39f2b26f5af5a152e","7db18883f3124911b6d22da55ad96961","97f3bc0070f2408f94231f2b6f76a563","650f9e5f309a41f582c3f2ad74d4764f","1f813f0a0c7f46368b201476b30ca3d3","a8c09e3d13ac4867affa9a67c5c42cd4","1660bfec765443a8a83869d7f88b754c","16941321dbe8495091d5540dda9347c3","412dde7bfac442eab1f0ab65e6db9a1e","5c48a94a05e14f2e9b1a75d7709f215c","336bdc8976804dc9b1d89bb00cdf46e8","23f8f02a80b64b878870d85e97a1f015","e80cda81b1874e0b8515ec0651a1d6f8","109bb73b21754333a45659e491912b5a","a69c081846f04b74883ae9cb04f2b688","903bcc6573974688af10cedbfaf3d8b0","3b40e595eaa94d7b9524385b59fcf64f","0fdba260ec8c4687b4db641cb7c8e8ba","45e625676ef7416487b12dbcc6e3e6d0","9939be72db884deda47981d92b7ef0d7","d289a5a293ad4016a41743f6938d9055","e1cf0e1ec86847a3bd34236ab5737347","af16bf78d15e4b28877940b8ee29ece0","628ec79d5cb745a28a1788785889a017","b182bb79c18844aca2d204ce886423ba","adae393c7a074ff293395b0d143e69b2","20ef975c6ba14f92abfb4befe21d261c","3fc55f5e40ff45ff9f997ce361c03553","0cb8bf3d19c4441aadebd44122892fad","0d6cdf90a91a4ed28e1229e82ca74318","aa8537edaf34404a9bde0f41385d38e5","12098ed0479946f19cbc4e5975ffd686","666303a75a644a73a82e607cea32fb8d","24d98c787a5c42d7a99c272d7c78f6ac","60c70b2a124e4bc2af7dea56f8d48149","7c9c166ab82047a1b874721fee55bda3","5c5bc4c35104455fad386b46b62a82c3","9125f3cf207b4858af4c7acecca46b32","3a3dee7df7594aed86854a98ec44edfd","e384831a0f4740848ac065fa7a1b7137","b5696a91fe3d434b81882ce28271cbd9","015d0ca0d94a4bffb23bb70ed10a6249","55fe3a581b9e491f80312485aee7998a","ce8271224c5b4e4d9cc3689761609b7f","a9002deb6426403ea5ceed99e6fc82dc","9775603b493a43e0be5e842aa57b6142","3404b887b9c24513b9f7318c9ab1c894","8325556011654611b0c5630624fbd66d","4b61b9fb427f4695ac3ccbb93567b4d7","2a49dc645054408eb6d60c83b73da43b","e5a48ee261ec44d98101f158c9ffbc49","93e726fa134a42f2a88da17a284449f0","6db36e153b7e4299af1fe2036711eb17","559a93cdf42d437691b34a59309d50fd","7ca647e4a4a54970a012f96c2e85ab60","bad13bac650d4b91a690c612f4a6fa6c","16f4209210d0498589701ad9b3fbac16","af397861f7ee448fb85d65d338803e54","3af8d440cbe64b2fbf91643292ca7e82","4a9246389a0a418895623761953441cc","eec23f87f8514499b6034d1603adec1e","4f26fa1774034d8992bedd6cbf85bbc8","4040555d15e04c418de2281b037f7ec2","42561c8567694b559ed5a88127e39337"]},"id":"lhb3I_Ip20Qp","outputId":"12f4d6ed-c608-4d2a-fa7e-6f81a1362a49"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c35d295e06ed4283bd29727809b54216","version_minor":0,"version_major":2},"text/plain":["Dl Completed...: 0 url [00:00, ? url/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fabb341a979a4c90a271a1dc91b9d77e","version_minor":0,"version_major":2},"text/plain":["Dl Size...: 0 MiB [00:00, ? MiB/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"349856e79cdb4d1080a0927d25255bb3","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteW1SFHA/imdb_reviews-train.tfrecord\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c48a94a05e14f2e9b1a75d7709f215c","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/25000 [00:00<?, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d289a5a293ad4016a41743f6938d9055","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteW1SFHA/imdb_reviews-test.tfrecord\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12098ed0479946f19cbc4e5975ffd686","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/25000 [00:00<?, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55fe3a581b9e491f80312485aee7998a","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteW1SFHA/imdb_reviews-unsupervised.tfrecord\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"559a93cdf42d437691b34a59309d50fd","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/50000 [00:00<?, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"]}],"source":["train_data, test_data = tfds.load(\n","    name=\"imdb_reviews\", \n","    split=('train[:80%]', 'test[80%:]'),\n","    as_supervised=True)"],"id":"lhb3I_Ip20Qp"},{"cell_type":"markdown","metadata":{"id":"ljzl3E_m20Qq"},"source":["Let's some create train examples and test examples. "],"id":"ljzl3E_m20Qq"},{"cell_type":"code","execution_count":null,"metadata":{"id":"IcN47gKh20Qq"},"outputs":[],"source":["train_examples_batch, train_labels_batch = next(iter(train_data.batch(20000)))\n","test_examples_batch, test_labels_batch = next(iter(test_data.batch(5000)))"],"id":"IcN47gKh20Qq"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNPuxNLA20Qq","outputId":"50548c1d-1bd4-433a-eaca-27869acbcf37"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=string, numpy=\n","array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\",\n","       b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.',\n","       b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.',\n","       b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.'],\n","      dtype=object)>"]},"metadata":{},"execution_count":12}],"source":["train_examples_batch[:4]"],"id":"aNPuxNLA20Qq"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_GIR4A_i20Qq","outputId":"60b30cee-6d6c-4ee0-95a6-315b3e69a379"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 0, 0, 1])>"]},"metadata":{},"execution_count":13}],"source":["train_labels_batch[:4]"],"id":"_GIR4A_i20Qq"},{"cell_type":"markdown","metadata":{"id":"cJPS6Db820Qr"},"source":["### 2. Preparing the model input with the BERT Tokenizer\n","\n","We use the 'bert-base-cased' from Huggingface as the underlying BERT model."],"id":"cJPS6Db820Qr"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181},"id":"zIYO76Jf20Qr","outputId":"03b0b382-c4d1-4170-e273-62e03e5e5d44","executionInfo":{"status":"error","timestamp":1664907320194,"user_tz":360,"elapsed":29,"user":{"displayName":"Krista Labovich","userId":"02513835265626180771"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8fdcdf13682d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'BertTokenizer' is not defined"]}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","bert_model = TFBertModel.from_pretrained('bert-base-cased')"],"id":"zIYO76Jf20Qr"},{"cell_type":"markdown","metadata":{"id":"MhmFyJgO20Qr"},"source":["Let's create a few training and test examples. For training time purposes, let's define a relatively short maximum length. We may modify the numbers later. "],"id":"MhmFyJgO20Qr"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0N5V-upe20Qr"},"outputs":[],"source":["num_train_examples = 2500\n","num_test_examples = 500\n","num_tiny_set = 5\n","\n","max_length = 80\n","\n","x_train = tokenizer([str(x.numpy())[2:] for x in train_examples_batch[:num_train_examples]], \n","              max_length=max_length,\n","              truncation=True,\n","              padding='max_length', \n","              return_tensors='tf')\n","y_train = train_labels_batch[:num_train_examples]\n","\n","\n","x_test = tokenizer([str(x.numpy())[2:] for x in test_examples_batch[:num_test_examples]], \n","              max_length=max_length,\n","              truncation=True,\n","              padding='max_length', \n","              return_tensors='tf')\n","y_test = test_labels_batch[:num_test_examples]\n","\n","\n","x_tiny = tokenizer([str(x.numpy())[2:] for x in test_examples_batch[:num_tiny_set]], \n","              max_length=max_length,\n","              truncation=True,\n","              padding='max_length', \n","              return_tensors='tf')\n","y_tiny = test_labels_batch[:num_tiny_set]"],"id":"0N5V-upe20Qr"},{"cell_type":"markdown","metadata":{"id":"eca-T27a20Qs"},"source":["Let us look at the class imbalance:"],"id":"eca-T27a20Qs"},{"cell_type":"code","execution_count":null,"metadata":{"id":"CwbStTgU20Qs"},"outputs":[],"source":["print('ratio of positive examples: ', np.sum(y_train)/len(y_train))"],"id":"CwbStTgU20Qs"},{"cell_type":"markdown","metadata":{"id":"OOlH8E7j20Qs"},"source":["Ok, slightly more negative examples in train set.\n","\n","What did the tokenizer do?\n","\n","The tokenizer created input ids, token type ids, and masks:"],"id":"OOlH8E7j20Qs"},{"cell_type":"code","execution_count":null,"metadata":{"id":"uE5RFO__20Qt"},"outputs":[],"source":["x_train.keys()"],"id":"uE5RFO__20Qt"},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0jFNJt520Qt"},"outputs":[],"source":["x_train.input_ids"],"id":"x0jFNJt520Qt"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eAlmKhC20Qt"},"outputs":[],"source":["x_train.token_type_ids"],"id":"2eAlmKhC20Qt"},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSayxIyq20Qt"},"outputs":[],"source":["x_train.attention_mask"],"id":"KSayxIyq20Qt"},{"cell_type":"markdown","metadata":{"id":"l1SqSJKK20Qu"},"source":["No surprises...\n","\n","**Questions:**\n","\n","* What are the purpose of each component?\n","* Why do the input ids all start off with 101?\n","\n"],"id":"l1SqSJKK20Qu"},{"cell_type":"markdown","source":["As we can see, the BERT model expects three inputs:\n","\n","* Input ids: BERT input sequence unambiguously represents both single text and text pairs. Sentences are encoded using the WordPiece tokenizer, which recursively splits the input tokens until a word in the BERT vocabulary is detected, or the token is reduced to a single char. As first token, BERT uses the CLS special token, whose embedded representation can be used for classification purposes. Moreover, at the end of each sentence, a SEP token is used, which is exploited for differentiating between the two input sentences in the case of text pairs.\n","* Input mask: Allows the model to cleanly differentiate between the content and the padding. The mask has the same shape as the input ids, and contains 1 anywhere the the input ids is not padding.\n","* Input types: Contains 0 or 1 indicating which sentence the token is a part of. For a single-sentence input, it is a vector of zeros."],"metadata":{"id":"X69L0v1ZcOdI"},"id":"X69L0v1ZcOdI"},{"cell_type":"markdown","source":["### 3. BERT"],"metadata":{"id":"uJfat0urcNVX"},"id":"uJfat0urcNVX"},{"cell_type":"markdown","metadata":{"id":"5_K0TWHY20Qu"},"source":["What are the outputs of bert_model, when applied to data?"],"id":"5_K0TWHY20Qu"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nzz1bQaH20Qu"},"outputs":[],"source":["bert_out = bert_model(x_tiny, output_hidden_states=True)"],"id":"Nzz1bQaH20Qu"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nYAwpiTi20Qu","outputId":"c9629fb0-9785-46be-f0ad-8126d2cab243"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":22}],"source":["len(bert_out)"],"id":"nYAwpiTi20Qu"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OHFAi_cE20Qu","outputId":"7891d7ca-3f22-457a-e01e-7c706c8c7265"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5, 80, 768)"]},"metadata":{},"execution_count":23}],"source":["bert_out[0].numpy().shape"],"id":"OHFAi_cE20Qu"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGsN8i_J20Qv","outputId":"65c4a85d-7548-403c-a013-c126cd430424"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5, 768)"]},"metadata":{},"execution_count":24}],"source":["bert_out[1].numpy().shape"],"id":"GGsN8i_J20Qv"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cEtt3MOl20Qv","outputId":"dfa5846a-b476-403f-eb14-ee81f8ebbf26"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["13"]},"metadata":{},"execution_count":25}],"source":["len(bert_out[2])"],"id":"cEtt3MOl20Qv"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iWatK-X20Qv","outputId":"a55ab5fd-e96e-42c8-be78-e1d07f20c5e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768]),\n"," TensorShape([5, 80, 768])]"]},"metadata":{},"execution_count":26}],"source":["[x.shape for x in bert_out[2]]"],"id":"6iWatK-X20Qv"},{"cell_type":"markdown","metadata":{"id":"rGRkzMP720Qv"},"source":["**Questions:**\n","* What are the interpretations of the 3 outputs?\n","* Are the respective dimensions as expected?\n"],"id":"rGRkzMP720Qv"},{"cell_type":"markdown","source":["\n","### 4. Building our Classification Model\n","\n","Let's build our classification model from scratch and run a few configurations.\n","\n","In particular, we will consider:\n","\n","* Optimizer choices\n","* number of bert layers to be re-trained\n","* effects of freezing and unfreezing\n"],"metadata":{"id":"BEu28QXIdHQb"},"id":"BEu28QXIdHQb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"gOeqcWJ820Qv"},"outputs":[],"source":["def create_classification_model(hidden_size = 200, \n","                                train_layers = -1, \n","                                optimizer=tf.keras.optimizers.Adam()):\n","    \"\"\"\n","    Build a simple classification model with BERT. Let's keep it simple and don't add dropout, layer norms, etc.\n","    \"\"\"\n","\n","    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids_layer')\n","    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='token_type_ids_layer')\n","    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask_layer')\n","\n","    bert_inputs = {'input_ids': input_ids,\n","                  'token_type_ids': token_type_ids,\n","                  'attention_mask': attention_mask}\n","\n","\n","    #restrict training to the train_layers outer transformer layers\n","    if not train_layers == -1:\n","\n","            retrain_layers = []\n","\n","            for retrain_layer_number in range(train_layers):\n","\n","                layer_code = '_' + str(11 - retrain_layer_number)\n","                retrain_layers.append(layer_code)\n","\n","            for w in bert_model.weights:\n","                if not any([x in w.name for x in retrain_layers]):\n","                    w._trainable = False\n","\n","\n","    bert_out = bert_model(bert_inputs)\n","\n","\n","    classification_token = tf.keras.layers.Lambda(lambda x: x[:,0,:], name='get_first_vector')(bert_out[0])\n","\n","\n","    hidden = tf.keras.layers.Dense(hidden_size, name='hidden_layer')(classification_token)\n","\n","    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n","\n","    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], \n","                                          outputs=[classification])\n","    \n","    classification_model.compile(optimizer=optimizer,\n","                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n","                            metrics='accuracy')\n","\n","\n","    return classification_model"],"id":"gOeqcWJ820Qv"},{"cell_type":"markdown","metadata":{"id":"EQCMCMOQ20Qv"},"source":["### 5. Experimentation\n","\n","Let us compare a few configurations:\n","\n","* 'default': Adam Optimizer with default parameters (lr=0.001), all BERT layers fine-tuned \n","* 'smaller learning rate': Adam Optimizer with lr=0.00005 parameters, all BERT layers fine-tuned \n","* 'frozen': Adam Optimizer with default parameters, all BERT layers frozen"],"id":"EQCMCMOQ20Qv"},{"cell_type":"markdown","source":["#### 5.1 Default"],"metadata":{"id":"J17NUjF2orVH"},"id":"J17NUjF2orVH"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApBuaAvk20Qw"},"outputs":[],"source":["classification_model = create_classification_model()     "],"id":"ApBuaAvk20Qw"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHIPLbqK20Qw","outputId":"4a9aa906-d985-45d6-a068-e871a863b79b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","313/313 [==============================] - 58s 136ms/step - loss: 0.7980 - accuracy: 0.4960 - val_loss: 0.6951 - val_accuracy: 0.5220\n","Epoch 2/5\n","313/313 [==============================] - 40s 127ms/step - loss: 0.7331 - accuracy: 0.5008 - val_loss: 0.7286 - val_accuracy: 0.5220\n","Epoch 3/5\n","313/313 [==============================] - 40s 127ms/step - loss: 0.7276 - accuracy: 0.4904 - val_loss: 0.6923 - val_accuracy: 0.5220\n","Epoch 4/5\n","313/313 [==============================] - 40s 126ms/step - loss: 0.7166 - accuracy: 0.5092 - val_loss: 0.6952 - val_accuracy: 0.4780\n","Epoch 5/5\n","313/313 [==============================] - 40s 126ms/step - loss: 0.7165 - accuracy: 0.4808 - val_loss: 0.6949 - val_accuracy: 0.4780\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb1b64ed710>"]},"metadata":{},"execution_count":29}],"source":["classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n","                         y_train,\n","                         validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask],\n","                         y_test),\n","                        epochs=5,\n","                        batch_size=8)\n","\n","#classification_model([x.input_ids, x.token_type_ids, x.attention_mask])"],"id":"SHIPLbqK20Qw"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4_R8aBD20Qw","outputId":"225d9cbf-0530-4341-fb8a-7e456e343131"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.4851759 ],\n","       [0.48517585],\n","       [0.48517635],\n","       [0.48517603],\n","       [0.4851758 ],\n","       [0.4851761 ],\n","       [0.48517603],\n","       [0.4851758 ],\n","       [0.4851759 ],\n","       [0.4851759 ],\n","       [0.4851758 ],\n","       [0.4851759 ],\n","       [0.4851759 ],\n","       [0.4851759 ],\n","       [0.4851758 ],\n","       [0.4851759 ]], dtype=float32)"]},"metadata":{},"execution_count":30}],"source":["classification_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n","                             batch_size=8, \n","                             steps=2)"],"id":"s4_R8aBD20Qw"},{"cell_type":"markdown","metadata":{"id":"wCDCZRYU20Qw"},"source":["What is this? All essentially the same prediction? And basically not better than always predicting the majority class for each example? It may seem like \"BERT is no good for this task\"?!\n","\n","Careful, not so! There are a number of changes one can consider:\n","\n","* Change the optimizer configuration\n","* Freeze some BERT layers - maybe for the entire training cycle or for thye first few epochs. \n","* Add more data\n","\n","\n","#### 5.2 Lower Learning Rate\n"],"id":"wCDCZRYU20Qw"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGUVNgrG20Qw","outputId":"b050ac7d-2f32-412d-f8c0-65176cff9759"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","313/313 [==============================] - 57s 135ms/step - loss: 0.5645 - accuracy: 0.7100 - val_loss: 0.4329 - val_accuracy: 0.7980\n","Epoch 2/5\n","313/313 [==============================] - 39s 125ms/step - loss: 0.3112 - accuracy: 0.8732 - val_loss: 0.4238 - val_accuracy: 0.8080\n","Epoch 3/5\n","313/313 [==============================] - 39s 125ms/step - loss: 0.1460 - accuracy: 0.9456 - val_loss: 0.6298 - val_accuracy: 0.7800\n","Epoch 4/5\n","313/313 [==============================] - 39s 125ms/step - loss: 0.0792 - accuracy: 0.9732 - val_loss: 0.7218 - val_accuracy: 0.7860\n","Epoch 5/5\n","313/313 [==============================] - 39s 125ms/step - loss: 0.0644 - accuracy: 0.9776 - val_loss: 1.1448 - val_accuracy: 0.7420\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[9.1157824e-04],\n","       [9.1122417e-03],\n","       [9.9915135e-01],\n","       [9.9999785e-01],\n","       [9.9997735e-01],\n","       [9.9999821e-01],\n","       [3.0629945e-04],\n","       [1.2434995e-03],\n","       [1.9111978e-01],\n","       [2.0054862e-02],\n","       [2.6297294e-02],\n","       [9.9996793e-01],\n","       [9.9995768e-01],\n","       [2.3948219e-04],\n","       [9.9996090e-01],\n","       [1.0069575e-02]], dtype=float32)"]},"metadata":{},"execution_count":31}],"source":["try:\n","    del classification_model\n","except:\n","    pass\n","\n","try:\n","    del bert_model\n","except:\n","    pass\n","\n","tf.keras.backend.clear_session()\n","bert_model = TFBertModel.from_pretrained('bert-base-cased')\n","\n","classification_model = create_classification_model(optimizer=tf.keras.optimizers.Adam(0.00005))\n","\n","classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n","                         y_train,\n","                         validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask],\n","                         y_test),\n","                        epochs=5,\n","                        batch_size=8)\n","\n","classification_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n","                             batch_size=8, \n","                             steps=2)"],"id":"NGUVNgrG20Qw"},{"cell_type":"markdown","metadata":{"id":"50bgnTSO20Qx"},"source":["That seemed to work! Looks like the learning rate really mattered! (Of course, we have not focused here on finding the model for the test accuracy. We simply wanted to 'get it to work').\n","\n","#### 5.3 Layer Freezing"],"id":"50bgnTSO20Qx"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hlc89P-h20Qx","outputId":"29382450-d470-4821-f44a-841cf82d9a56"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","313/313 [==============================] - 27s 69ms/step - loss: 0.7339 - accuracy: 0.6368 - val_loss: 0.5789 - val_accuracy: 0.7080\n","Epoch 2/5\n","313/313 [==============================] - 19s 61ms/step - loss: 0.5899 - accuracy: 0.6904 - val_loss: 0.5836 - val_accuracy: 0.7020\n","Epoch 3/5\n","313/313 [==============================] - 19s 60ms/step - loss: 0.5864 - accuracy: 0.6936 - val_loss: 0.5640 - val_accuracy: 0.7100\n","Epoch 4/5\n","313/313 [==============================] - 19s 60ms/step - loss: 0.5861 - accuracy: 0.7028 - val_loss: 0.5756 - val_accuracy: 0.6960\n","Epoch 5/5\n","313/313 [==============================] - 19s 60ms/step - loss: 0.5668 - accuracy: 0.7012 - val_loss: 0.5550 - val_accuracy: 0.7180\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.32855806],\n","       [0.14014086],\n","       [0.72288543],\n","       [0.954685  ],\n","       [0.6062221 ],\n","       [0.81637114],\n","       [0.3781842 ],\n","       [0.70118695],\n","       [0.50046664],\n","       [0.27207872],\n","       [0.12228752],\n","       [0.67316914],\n","       [0.8727204 ],\n","       [0.14307736],\n","       [0.45966038],\n","       [0.11654742]], dtype=float32)"]},"metadata":{},"execution_count":32}],"source":["try:\n","    del classification_model\n","except:\n","    pass\n","\n","try:\n","    del bert_model\n","except:\n","    pass\n","\n","tf.keras.backend.clear_session()\n","bert_model = TFBertModel.from_pretrained('bert-base-cased')\n","\n","classification_model = create_classification_model(train_layers=0)\n","\n","classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n","                         y_train,\n","                         validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask],\n","                         y_test),\n","                        epochs=5,\n","                        batch_size=8)\n","\n","classification_model.predict([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n","                             batch_size=8, \n","                             steps=2)"],"id":"hlc89P-h20Qx"},{"cell_type":"markdown","metadata":{"id":"-QnwgX-v20Qx"},"source":["That 'worked' too! As expected, the final validation loss is larger and the validation accuracy is smaller though.\n","\n","**Questions:**\n","* is that expected? \n","* What else is different?\n"],"id":"-QnwgX-v20Qx"},{"cell_type":"markdown","source":["## Part II Fine-tune BERT at a higher level of abstraction"],"metadata":{"id":"VS_8Q-TSkPd3"},"id":"VS_8Q-TSkPd3"},{"cell_type":"code","source":["from transformers import TFAutoModelForSequenceClassification"],"metadata":{"id":"E5wzBVlmkQR4"},"id":"E5wzBVlmkQR4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fkf7uZANkVPK","outputId":"c997de6e-6c61-4b28-8350-3bb79e5d30b8"},"id":"fkf7uZANkVPK","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n","          y_train,\n","          validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], \n","                           y_test),\n","          epochs=3, \n","          batch_size=8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxb-UEzIkYFg","outputId":"8638e639-2833-4180-8a06-1bd37653c3f8"},"id":"oxb-UEzIkYFg","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","313/313 [==============================] - 58s 134ms/step - loss: 0.5689 - sparse_categorical_accuracy: 0.6880 - val_loss: 0.4320 - val_sparse_categorical_accuracy: 0.7940\n","Epoch 2/3\n","313/313 [==============================] - 39s 125ms/step - loss: 0.3502 - sparse_categorical_accuracy: 0.8616 - val_loss: 0.4140 - val_sparse_categorical_accuracy: 0.8100\n","Epoch 3/3\n","313/313 [==============================] - 39s 125ms/step - loss: 0.2069 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.4955 - val_sparse_categorical_accuracy: 0.7980\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb21c5d3410>"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["model_1 = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=1)\n","model_1.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n","              loss='binary_crossentropy', \n","              metrics=['accuracy']\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yMJlI6erJm4","outputId":"3570e972-3325-479d-927a-4ded44d4b434"},"id":"_yMJlI6erJm4","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model_1.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask], \n","          y_train,\n","          validation_data=([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask], \n","                           y_test),\n","          epochs=3, \n","          batch_size=8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0Usi7dKrU2O","outputId":"ee642c4c-fe63-4603-e11a-21a0d6b76392"},"id":"-0Usi7dKrU2O","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","313/313 [==============================] - 56s 133ms/step - loss: 0.6942 - accuracy: 0.6744 - val_loss: 0.4524 - val_accuracy: 0.8160\n","Epoch 2/3\n","313/313 [==============================] - 39s 125ms/step - loss: 0.5302 - accuracy: 0.8048 - val_loss: 0.5111 - val_accuracy: 0.8200\n","Epoch 3/3\n","313/313 [==============================] - 39s 125ms/step - loss: 0.4830 - accuracy: 0.8720 - val_loss: 0.6554 - val_accuracy: 0.8020\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb1adb92090>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["y_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4GSEHp8jrV01","outputId":"f976daaf-cb08-448e-b8c2-298ee0ab9d15"},"id":"4GSEHp8jrV01","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2500,), dtype=int64, numpy=array([0, 0, 0, ..., 1, 0, 0])>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":[],"metadata":{"id":"AV_Ho3FWtxH9"},"id":"AV_Ho3FWtxH9","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["https://www.analyticsvidhya.com/blog/2021/05/all-you-need-to-know-about-bert/"],"metadata":{"id":"Mq2CCvUKve63"},"id":"Mq2CCvUKve63"},{"cell_type":"code","source":[],"metadata":{"id":"rGv92T9MvfRb"},"id":"rGv92T9MvfRb","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c35d295e06ed4283bd29727809b54216":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bbb8afed387d48a18bfb6a78440835d4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9c2a5bcad9ec4132a6577a90d24fc154","IPY_MODEL_0c6b274773cc4176bd615d3a698f7d60","IPY_MODEL_b260cc10b4c543a2ad3a26203b2a702a"]}},"bbb8afed387d48a18bfb6a78440835d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c2a5bcad9ec4132a6577a90d24fc154":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8fb595e299654cf3a49a63f7f33d58c8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Dl Completed...: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8983a6350a68487596a4501d48c266b3"}},"0c6b274773cc4176bd615d3a698f7d60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_46b3f1c879ed4e52bfad9eb04710e2d6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_49711110f80f4c7ead3d9ba6e878bab7"}},"b260cc10b4c543a2ad3a26203b2a702a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fc0d2f12f4db40fc98379355d33d3fad","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:08&lt;00:00,  8.02s/ url]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3ebb5986dca843d3860d4ddca5e606a0"}},"8fb595e299654cf3a49a63f7f33d58c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8983a6350a68487596a4501d48c266b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"46b3f1c879ed4e52bfad9eb04710e2d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"49711110f80f4c7ead3d9ba6e878bab7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc0d2f12f4db40fc98379355d33d3fad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3ebb5986dca843d3860d4ddca5e606a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fabb341a979a4c90a271a1dc91b9d77e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fad3be436c8442cf8fcfc7a5a330bcd0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_47b445186d064cd580597b11a47b87e1","IPY_MODEL_6d323c59c4b14839baace79b773bfdd3","IPY_MODEL_523ac7d2e55c467a9200948d423a6041"]}},"fad3be436c8442cf8fcfc7a5a330bcd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47b445186d064cd580597b11a47b87e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bbfb77bca4ef44239503f7674c4f8c09","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Dl Size...: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33875c0e82bc427cab6a8a4ff90136d9"}},"6d323c59c4b14839baace79b773bfdd3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d1dcf05f652d47acb31644a4805af47e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_62fa216c14b345cd9ed0fdabace5b1c7"}},"523ac7d2e55c467a9200948d423a6041":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_20810f74e68840168bdd9eb30bdf8ede","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 80/80 [00:07&lt;00:00, 18.72 MiB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46e47b077d114a8fabd80d40f1edd2ed"}},"bbfb77bca4ef44239503f7674c4f8c09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"33875c0e82bc427cab6a8a4ff90136d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1dcf05f652d47acb31644a4805af47e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"62fa216c14b345cd9ed0fdabace5b1c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"20810f74e68840168bdd9eb30bdf8ede":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46e47b077d114a8fabd80d40f1edd2ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"349856e79cdb4d1080a0927d25255bb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_84e8f45820624362b45e516a2c9ef8f9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_43b9a5ed213949c39f2b26f5af5a152e","IPY_MODEL_7db18883f3124911b6d22da55ad96961","IPY_MODEL_97f3bc0070f2408f94231f2b6f76a563"]}},"84e8f45820624362b45e516a2c9ef8f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43b9a5ed213949c39f2b26f5af5a152e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_650f9e5f309a41f582c3f2ad74d4764f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1f813f0a0c7f46368b201476b30ca3d3"}},"7db18883f3124911b6d22da55ad96961":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a8c09e3d13ac4867affa9a67c5c42cd4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1660bfec765443a8a83869d7f88b754c"}},"97f3bc0070f2408f94231f2b6f76a563":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_16941321dbe8495091d5540dda9347c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 24704/0 [00:09&lt;00:00, 2411.48 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_412dde7bfac442eab1f0ab65e6db9a1e"}},"650f9e5f309a41f582c3f2ad74d4764f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1f813f0a0c7f46368b201476b30ca3d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8c09e3d13ac4867affa9a67c5c42cd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1660bfec765443a8a83869d7f88b754c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"16941321dbe8495091d5540dda9347c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"412dde7bfac442eab1f0ab65e6db9a1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c48a94a05e14f2e9b1a75d7709f215c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_336bdc8976804dc9b1d89bb00cdf46e8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_23f8f02a80b64b878870d85e97a1f015","IPY_MODEL_e80cda81b1874e0b8515ec0651a1d6f8","IPY_MODEL_109bb73b21754333a45659e491912b5a"]}},"336bdc8976804dc9b1d89bb00cdf46e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"23f8f02a80b64b878870d85e97a1f015":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a69c081846f04b74883ae9cb04f2b688","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_903bcc6573974688af10cedbfaf3d8b0"}},"e80cda81b1874e0b8515ec0651a1d6f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b40e595eaa94d7b9524385b59fcf64f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":24999,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0fdba260ec8c4687b4db641cb7c8e8ba"}},"109bb73b21754333a45659e491912b5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_45e625676ef7416487b12dbcc6e3e6d0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 24999/25000 [00:00&lt;00:00, 114616.72 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9939be72db884deda47981d92b7ef0d7"}},"a69c081846f04b74883ae9cb04f2b688":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"903bcc6573974688af10cedbfaf3d8b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b40e595eaa94d7b9524385b59fcf64f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0fdba260ec8c4687b4db641cb7c8e8ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45e625676ef7416487b12dbcc6e3e6d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9939be72db884deda47981d92b7ef0d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d289a5a293ad4016a41743f6938d9055":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1cf0e1ec86847a3bd34236ab5737347","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_af16bf78d15e4b28877940b8ee29ece0","IPY_MODEL_628ec79d5cb745a28a1788785889a017","IPY_MODEL_b182bb79c18844aca2d204ce886423ba"]}},"e1cf0e1ec86847a3bd34236ab5737347":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af16bf78d15e4b28877940b8ee29ece0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_adae393c7a074ff293395b0d143e69b2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20ef975c6ba14f92abfb4befe21d261c"}},"628ec79d5cb745a28a1788785889a017":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3fc55f5e40ff45ff9f997ce361c03553","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0cb8bf3d19c4441aadebd44122892fad"}},"b182bb79c18844aca2d204ce886423ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d6cdf90a91a4ed28e1229e82ca74318","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 24660/0 [00:07&lt;00:00, 3706.35 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa8537edaf34404a9bde0f41385d38e5"}},"adae393c7a074ff293395b0d143e69b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20ef975c6ba14f92abfb4befe21d261c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fc55f5e40ff45ff9f997ce361c03553":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0cb8bf3d19c4441aadebd44122892fad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d6cdf90a91a4ed28e1229e82ca74318":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa8537edaf34404a9bde0f41385d38e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"12098ed0479946f19cbc4e5975ffd686":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_666303a75a644a73a82e607cea32fb8d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_24d98c787a5c42d7a99c272d7c78f6ac","IPY_MODEL_60c70b2a124e4bc2af7dea56f8d48149","IPY_MODEL_7c9c166ab82047a1b874721fee55bda3"]}},"666303a75a644a73a82e607cea32fb8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"24d98c787a5c42d7a99c272d7c78f6ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5c5bc4c35104455fad386b46b62a82c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9125f3cf207b4858af4c7acecca46b32"}},"60c70b2a124e4bc2af7dea56f8d48149":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3a3dee7df7594aed86854a98ec44edfd","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":24999,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e384831a0f4740848ac065fa7a1b7137"}},"7c9c166ab82047a1b874721fee55bda3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b5696a91fe3d434b81882ce28271cbd9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 24999/25000 [00:00&lt;00:00, 105908.74 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_015d0ca0d94a4bffb23bb70ed10a6249"}},"5c5bc4c35104455fad386b46b62a82c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9125f3cf207b4858af4c7acecca46b32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a3dee7df7594aed86854a98ec44edfd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e384831a0f4740848ac065fa7a1b7137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5696a91fe3d434b81882ce28271cbd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"015d0ca0d94a4bffb23bb70ed10a6249":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55fe3a581b9e491f80312485aee7998a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ce8271224c5b4e4d9cc3689761609b7f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a9002deb6426403ea5ceed99e6fc82dc","IPY_MODEL_9775603b493a43e0be5e842aa57b6142","IPY_MODEL_3404b887b9c24513b9f7318c9ab1c894"]}},"ce8271224c5b4e4d9cc3689761609b7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9002deb6426403ea5ceed99e6fc82dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8325556011654611b0c5630624fbd66d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4b61b9fb427f4695ac3ccbb93567b4d7"}},"9775603b493a43e0be5e842aa57b6142":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2a49dc645054408eb6d60c83b73da43b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e5a48ee261ec44d98101f158c9ffbc49"}},"3404b887b9c24513b9f7318c9ab1c894":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_93e726fa134a42f2a88da17a284449f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 49827/0 [00:18&lt;00:00, 3553.27 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6db36e153b7e4299af1fe2036711eb17"}},"8325556011654611b0c5630624fbd66d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4b61b9fb427f4695ac3ccbb93567b4d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a49dc645054408eb6d60c83b73da43b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e5a48ee261ec44d98101f158c9ffbc49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"93e726fa134a42f2a88da17a284449f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6db36e153b7e4299af1fe2036711eb17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"559a93cdf42d437691b34a59309d50fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7ca647e4a4a54970a012f96c2e85ab60","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bad13bac650d4b91a690c612f4a6fa6c","IPY_MODEL_16f4209210d0498589701ad9b3fbac16","IPY_MODEL_af397861f7ee448fb85d65d338803e54"]}},"7ca647e4a4a54970a012f96c2e85ab60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bad13bac650d4b91a690c612f4a6fa6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3af8d440cbe64b2fbf91643292ca7e82","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a9246389a0a418895623761953441cc"}},"16f4209210d0498589701ad9b3fbac16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_eec23f87f8514499b6034d1603adec1e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":50000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":49999,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4f26fa1774034d8992bedd6cbf85bbc8"}},"af397861f7ee448fb85d65d338803e54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4040555d15e04c418de2281b037f7ec2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 49999/50000 [00:00&lt;00:00, 175593.41 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_42561c8567694b559ed5a88127e39337"}},"3af8d440cbe64b2fbf91643292ca7e82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4a9246389a0a418895623761953441cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eec23f87f8514499b6034d1603adec1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4f26fa1774034d8992bedd6cbf85bbc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4040555d15e04c418de2281b037f7ec2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"42561c8567694b559ed5a88127e39337":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":5}
